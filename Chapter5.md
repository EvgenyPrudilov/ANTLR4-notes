
--- 5.0 ---

Будем учиться строить грамматику. Посмотрим на самые распространённые лексические и синтаксические структуры языка и узнаем, как их можно выразить в ANTLR4 нотации. Но для этого нужно понимать эти языковые паттерны и уметь их идентифицировать.

Многие языки похожи, потому что создатели имеют склонность перенимать нотацию из математики. Даже на лексическом уровне многие языки используют те же структуры: идентификаторы, числа, строки, ...

Четыре основных языковых паттерна:

* **Последовательность**(Sequence) - выражает последовательность элементов(как при инициализации массива).
* **Выбор**(Choice) - выбор одной из нескольких альтернатив фраз.
* **Зависимость токенов**(Token dependence) - наличие одного токена требует наличие другого соответствующего токена-двойника(как правая и левая скобки).
* **Вложенная фраза**(Nested phrase) - конструкция вроде арифметических выражений, где мы можем одно выражение вкладывать в другое.
Чтобы мы могли выражать эти паттерны, нам нужны лишь такие грамматические элементы: альтернативы, **ссылки на токены**(token references) и **ссылки на правила**(rule references) - это всё есть в **BNF**(Backus-Naur-Format). Для удобства мы будем группировать их в **субправила**(subrules) - это правила в скобках. Они могут быть: опциональными(?), встречаться ноль или больше раз(*) или один или больше раз(+) - это всё есть в **EBNF**(Extended Backus-Naur-Format).

--- 5.1 ---

Грамматика состоит из заголовка, который именует грамматику и набора вызывающих друг друга правил. Правильная грамматика отражает **функциональную декомпозицию**(functional decomposition) из мира программирования, т.е идём сверху(от крупных структур) вниз(к более мелким). Значит, сначала нужно найти имя для самой крупной структуры, которая будет первым правилом(для XML это мог бы быть document; для CSV - file; ...). Например:

```
file: "последовательность строк с терминирующим \n"
```

Затем мы опускаемся на уровень ниже и решаем Что будет справа от имени правила. И так далее, пока не получим грамматику(в грубом виде, конечно):

```
file: "последовательность строк(row) с терминирующим \n" 
row: "последовательность полей(fields), разделённых запятыми" 
field: "число или строка"
```

--- 5.2 ---

Хорошо, если уже имеется грамматика(не в ANTLR4 формате) - она поможет нам организовать свою(по крайней мере мы там можем узнать подходящие имена для правил). Не нужно рассматривать её как кусок кода, скорее - это просто руководство для написания своей грамматики.

Важно понимать, что есть некоторые ограничения, которые мы должны применять при парсинге или лексическом анализе, но не на уровне грамматики, таким образом разгружая эту грамматику. Например, в документации по XML говориться, что где-то в тегах пробелы допустимы, а где-то нет. Вместо того, чтобы описывать это с помощью грамматики, мы можем в нашем лексере эти пробелы просто выкидывать. Или, например, там говориться, что в теге <?xml ...> у нас есть только два атрибута: encoding и standalone. Но нам проще разрешить любой атрибут, а уже при парсинге проверять эти ограничения.

--- 5.3 ---

**Паттерн Последовательность** - представляет собой последовательность элементов. Например, объявление переменной(тип + идентификатор + ...), последовательность методов в классе, или последовательность комманд для POP протокола - даже сами команды будут последовательностями(обычно требуется какое-то ключевое слово, заним - операторы, и далее конец строки):

```
retr: 'RETR' INT '\n' ;
```

Чтобы выразить последовательность, в которой один или больше элементов, нужно использовать + оператор **субправила**(subrule). Например, (INT)+ означает последовательность произвольной длины. Если мы хотим сказать, что последовательность может быть пустой, то нужно использовать * оператор - он аналогичен циклу в языках программирования(так он собственно и реализован). Для выражения опциональности мы используем ? оператор.

Есть две вариации паттерна последовательности:

* **с терминатором**(sequence with terminator) - последовательность произвольной(возможно нулевой) длины, разделённая токеном(обычно новой строкой или точкой с запятой)
* **с разделителем**(sequence with separator) - непустая последовательность произвольной длины, разделённая токеном(обычно запятой, точкой или точкой с запятой). Например:

```
file : (row '\n')* ;
row  : field (',' field)* ; 
field: INT ;
```

В правиле rule мы используем терминирующий паттерн, где токен '\n' терминирует каждый элемент последовательности. В правиле row используется разделяющий паттер, где ',' разделяет поля.

Так мы определяем последовательность **предложений**(statements) в Java:

```
stats : (stat ';')* ;
```

А так - список выражений:

```
exprList : exrp (',' expr)* ;
```

**Паттерн Выбор**(Choice) - даёт возможность одну из **альтернатив**(alvernatives) (или ещё называют productions - как правильно перевести?). Чтобы выразить это, мы используем символ | - это как "or" оператор в ANTLR4 правилах. Например:

```
field : INT | STRING ;
```

**Паттерн Зависимость токенов**(Token dependence) - наличие одного токена требует наличие другого соответствующего токена-двойника. Для этого мы в правиле указываем оба символа, обычно для группироваки элементов. Например, для задания вектором, мы можем использовать:

```
vector : '[' INT+ ']' ; // [1], [1 2], [1 2 3], ...
```

Мы видем этот паттерн при объявлении массивов - [], функций - (), методом - (), объектов - {}, ... Важно, что символы не должны быть "двойниками" - они могут различаться, например, как в тернарном операторе: a ? b : c. Ещё важно, что наличие совпадающих символов не означает, что последовательности(вроде векторов) должны быть вложенными(хотя обычно это так).

Паттерн Вложенная фраза(Nested phrase) - такая фраза имеет определённую структуру, и в ней есть подфразы, имеющие такую же структуру. Короче - такие фразы можно вкладывать в друг друга. Пример: арифметические выражения, блоки видимости как в Си, ... . В грамматике мы это выражаем через рекурсивные правила. Пример:

stat: 'while' '(' expr ')' stat | '{' stat* '}' ... ;

Здесь stat прямо рекурсивно(directly recursive), т.к. ссылается на себя прямо в своих альтернативах. Вариант с косвенной рекурсией(indirectly recursive):

stat: 'while' '(' expr ') stat | block ... ; block: '{' stat* '}' ;

Здесь правила stat и block взаимно косвенно рекурсивны.

Ключевая нотация ANTLR4 грамматики: x - соответствует токену, ссылке на правило или подправилу с именем x x y ... z - соответствует последовательности элементов в правиле (... | ... | ...) - подправило с множеством альтернатив x? - x встречается 0 или 1 раз x* - x встречается 0 или больше раз x+ - x встречается 1 или больше раз r: ... ; - определяет правило с именем r r: ... | ... | ... ; - определяет правило с именем r с множеством альтернатив

--- 5.4 ---

Выражения всегда было трудно реализовать с помощью парсера рекурсивного спуска, прежде всего потому, что 1) грамматика иногда двусмысленна и 2) в спецификациях используется левая рекурсия(left recursion).

Представим простой язык для арифметических выражений. Понятно и естественно, что выражение - это пара подвыражений, связанных каким-либо оператором. Хочется выразить это вот так:

expr : expr '*' expr | expr '+' expr | INT ;

Проблема в том, что правило может двусмысленно для некоторых выражений. Если мы имеем простые выражения, вроде 1 + 2, 3 * 2 - всё хорошо. Но что если у нас будет такое выражение: 1 + 2 * 3 ? Его можно интерпретировать двумя разными способами: (1 + 2) * 3 и 1 + (2 * 3). Это вопрос приоритета операторов(operator precedence), а традиционная грамматика просто не может выразить это. Поэтому ANTLR4 решает это так: просто выбирается первая подходящая альтернатива - таким образом позволяя нам неявно определять приоритет. Пример выше будет разрешён в пользу умножения: 1 + (2 * 3).

По умолчанию, в ANTLR4 ассоциативность у операторов левая, но иногда нужна правая(например, для оператора степени). В таком случае нужно использовать опцию assoc:

expr : expr '^'<assoc=right> expr | INT ;

Леворекурсивное правило(left-recursive rule) - правило, которое явно или неявно вызывает себя с левого края альтернативы. Бывают также право-рекурсивные правила(right recursive rules). ANTLR4 справляется с явной левой рекурсией(как в примерах выражения выше), а с неявной - нет. Т.о. у нас будет проблема здесь:

expr : expo | ... ; expo : expr '^'<assoc=right> expr ;

Многие опытные разработчики компиляторов пишут парсеры рекурсивного спуска в ручную, чтобы выжать максимум производительности и иметь полный контроль над восстановлением после ошибки(error recovery). И вместо того, чтобы писать код для множества правил, они часто используют парсер с учетом приоритета операторов(??? хз как переводить)(operator precedence parser). ANTLR4 использует более мощную идею - он заменяет явную левую рекурсию циклом, который сравнивает приоритет предыдущего и следующего операторов.

В предыдущей версии ANTLR необходимо было такие правила с левой рекурсией переписывать, чтобы получить плавило для каждого уровня приоритета. Например, пример выше с выражениями можно переписать так:

expr : addExpr ; addExpr : multExpr ('+' multExpr)* ; multExpr: atom ('' atom) ; atom : INT ;

Сложно воспринимать. ANTLR4 позволяет писать это проще, короче и понятнее, как мы сделали это раньше.

--- 5.5 ---

Для для правил лексера мы используем по сути ту же нотацию. Разница лишь в том, что парсеры распознают грамматическую структуру в потоке токенов, а лексеры - в потоке символов. И те и другие правила можно хранить в одном файле, поэтому нам нужно как-то их различать, поэтому правила для парсера именуются маленькими буквами, а для лексера - БОЛЬШИМИ.

Для ключевых слов, оператором и пунктуации нам обычно не нужны лексические правила, т.к. мы можем на них ссылаться явно в правилах для парсера: 'while', '', '++', ... Но кто-то предпочитает использовать лексическое MULT вместо '', что позволяет одним махом изменить символ на другой во всех местах грамматики.

Чтобы определить правило для идентификатора(ненулевая последовательность символов в нижнем и верхнем регистрах), можно использовать такое правило:

ID : ('a'..'z' | 'A'..'Z')+ ;

Новинка: 'a'..'z' - обозначает диапазон символов включительно(коды ASCII от 97 до 122). Если нужно использовать Юникод, нужно явно указывать код - '\uXXXX'. Но для удобства можно использовать некоторые удобные регулярные выражения, вроде

ID : [a-zA-Z]+ ;

Такие правила могут конфликтовать с другими лексическими правилами или с ссылками на них из правил. Например:

enumDef : 'enum' '{' ... '}' ; FOR : 'for' ; ID : [a-zA-Z]+ ;

Правило ID также может соответствовать ключевым словам 'enum' и 'for'.

ANTLR4 собирает все литералы(типо 'enum') из правил. Они принадлежат лексическим правилам и будут находиться(как бы в иерархии выбора) после правил парсера, НО до явно объявленных лексических правил. А сам ANTLR4 решает эту неопределённость между лексическими правилами так: он просто выбирает первое подходящее. Поэтому правило ID должно быть после всех правил, с которыми оно может конфликтовать. В данном случае у 'enum' и FOR будет приоритет над ID. Но т.к. ANTLR4 строит эту иерархию, можно предыдущий пример записать так:

FOR : 'for' ; ID : [a-zA-Z]+ ; enumDef : 'enum' '{' ... '}' ;

Целые числа:

INT1 : '0'..'9'+ ; INT2 : [0-9]+ ;

Вещественные числа(без экспоненты для простоты):

FLOAT : DIGIT+ '.' DIGIT* | '.' DIGIT+ ; fragment DIGIT : [0-9] ;

Если перед лексическим правилом написать fragment, то мы 1) сообщим ANTLR4, что это правило используется только в других лексических правилах и 2) это не токен сам по себе, а значит мы не можем использовать его в правилах парсера.

Строковые литералы:

STRING : '"' .*? '"' ;

Оператор "точка"(dot wildcard operator) заменяется любым символом. Значит, .* соответствует последовательности из 0 или более символов. Знак вопроса здесь говорит, что не нужно жадничать(nongreedy) - собрать минимальное количество символов, но так, чтобы само правило сработало(чтобы также встретились кавычки по бокам). Вариант .* является жадным(greedy) - соберёт все, что сможет.

Строковые литералы с escape-последовательностями:

STRING : '"' (ESC | .)*? '"' ; fragment ESC : '\"' | '\\' ;

В самом ANTLR4 мы также должны экранировать символы.

Скорее всего мы хотим игнорировать пробельные символы и комментарии, чтобы не указывать их опциональными повсюду в правилах парсера, например так:

assign : ID (WS | COMMENT)? '=' (WS | COMMENT)? expr (WS | COMMENT)? ;

Чтобы указать, что их нужно игнорировать мы можем использовать команду skip(одна из множества команд для оператора ->):

LINE_COMMENT : '//' .? '\r'? '\n' -> skip ; COMMENT : '/' .? '/' -> skip ; WS1 : (' ' | '\t' | '\r' | '\n')+ -> skip ; WS2 : [ \t\r\n]+ -> skip ;

Но иногда могут возникнуть проблемы, например с символом '\n': иногда это просто символ новой строки, а иногда может быть признаком окончания команды. Т.е. он может быть контекстно-чувствительным(context-sensitive). Это будет обсуждаться позже.

--- 5.6 ---

Нужно определить грань между парсером и лексером. Лексические правила тоже могут могут использовать рекурсию, так что они могут выражать то же, что и правила парсера. Т.о. мы можем проверять грамматическую структуру с помощью парсера, или, наоборот, мы можем рассматривать каждый символ как отдельный токен для парсера(парсеры без сканера/лексера - scannerless/lexerless parsers).

Есть набор эмпирических правил:

Нужно найти и выбросить всё, что не имеет смысла для парсера(пробельные символы, комментарии, ...).
Распознавать идентификаторы, числа, строки и ключевые слова в лексере(у парсера больше накладных расходов, поэтому не стоит заставлять его складывать цифры, чтобы получить числа).
Объединить в один токен все лексические структуры, которые парсер не различает. Например, если мы с целыми и вещественными числами обращаемся одинаково, тогда их можно объединить в один токен NUMBER.
Объединить в один токен всё то, что парсер рассматривает как единое целое. Например, парсеру может быть всё равно, что находится в XML теге - лексер может это всё поместить в единый токен TAG.
Если парсеру нужно обрабатывать содержимое текста, тогда лексеру лучше передавать отдельные компоненты как токены.
Пример - мы хотим просто посчитать количество строк в файле:

file : NL+ ; STUFF : ~'\n+ -> skip ; NL : '\n' ;

Оператор ~x обозначает "всё, кроме x".

Пример - мы хотим читать IP адреса из логов:

file : row+ ; row : IP STRING INT NL ;

IP : INT '.' INT '.' INT '.' INT ; INT : [0-9]+ ; STRING: '"' .*? '"' ; NL : '\n' ; WS : ' ' -> skip ;

Предположим, что нам требуется распарсить строку IP адреса и получить числа. Это можно сделать с помощью библиотечной функции split('.') в парсере. Но можно распознать эти числа в лексере и просто передать парсеру:

file  : row+ ; row   : ip STRING INT NL ; ip    : INT '.' INT '.' INT '.' INT ;

INT   : [0-9]+ ; STRING: '"' .*? '"' ; NL    : '\n' ; WS    : ' ' -> skip ;

Это пример того насколько просто передвигать грань между парсером и лексером.
